<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://kayanerobach.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://kayanerobach.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-04-07T14:32:24+00:00</updated><id>https://kayanerobach.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Flexible Record Linkage</title><link href="https://kayanerobach.github.io/blog/2024/flexible-record-linkage/" rel="alternate" type="text/html" title="Flexible Record Linkage"/><published>2024-04-02T11:46:00+00:00</published><updated>2024-04-02T11:46:00+00:00</updated><id>https://kayanerobach.github.io/blog/2024/flexible-record-linkage</id><content type="html" xml:base="https://kayanerobach.github.io/blog/2024/flexible-record-linkage/"><![CDATA[<p>Combining data from various sources such as observational studies and municipality registries or hospital databases empowers researchers to explore innovative questions and improve models. However, the lack of a unique identifier often poses challenges. Natural problems like counting casualties require distinguishing individuals in registers that may contain duplicates when bodies are listed by several organisations. Conducting healthcare longitudinal studies require follow up information that is often concealed due to privacy considerations.</p> <p>Record linkage procedures determine whether pairs of observations collected on different occasions belong to the same individual (referred to as links) using partially identifying variables (e.g. initials, birth year, zipcode), herafter denoted PIVs. The complexity of this problem stems from the sub-par reliability of those variables and their low discriminative power, due to limited unique values. Furthermore, since everyone is often uniquely represented in each file, records from one file can maximally be linked with one record in the other file. Linkage decisions are thus interdependent, adding complexity to the task.</p> <p>Existing methodologies typically involve a compromise between computational efficiency and accuracy. Traditional approaches simplify this task by condensing information, yet they neglect dependencies among linkage decisions and disregard the one-to-one relationship required to establish coherent links. Modern approaches offer a comprehensive representation of the data generating process, at the expense of substantial computational overhead and reduced flexibility.</p> <p>This project proposes a flexible method to determine the set of links, that adapts to varying data complexities, addressing registration errors, including inaccuracies and missing values, and accommodating changes of the identifying information over time. Taking account of zip code temporal dynamics for instance holds importance in healthcare longitudinal studies; in the particular case of survival analysis long term follow-up are crucial, which increases the probability to move.</p> <p>To estimate the common set of records, we build a statistical model that leverages the latent representation of the partially identifying information embedded in the data generation process, and ultimately derive a linkage estimate. We estimate the model parameters represented as input nodes on the probabilistic graphical model hereafter, using a Stochastic Expectation Maximisation algorithm. <br/></p> <div class="exampletest"> <div align="center"> <br/> <script type="text/tikz">
\begin{tikzpicture}
\node[draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (gamma) at (0,4) {$\gamma$};
\node[shape=circle, draw={rgb:red,0;green,147;blue,175}, dashed, minimum size=1cm] (delta) at (0,2) {$\Delta$};
\node[draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (eta) at (0,0) {$\eta$};
\node[draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (alpha) at (0,-2) {$\alpha$};
\node[shape=circle, dashed, draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (HA) at (-3,-2) {$H^A$};
\node[shape=circle, dashed, draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (HB) at (3,-2) {$H^B$};
\node[draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (phi) at (0,-4) {$\phi$};
\node[shape=circle, draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (GA) at (-4.5,-4) {$G^A$};
\node[shape=circle, draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (GB) at (4.5,-4) {$G^B$};
\path [-stealth] (gamma) edge (delta);
\path [-stealth] (delta) edge (HA);
\path [-stealth] (delta) edge (HB);
\path [-stealth] (eta) edge (HA);
\path [-stealth] (eta) edge (HB);
\path [-stealth] (alpha) edge (HA);
\path [-stealth] (alpha) edge (HB);
\path [-stealth] (HA) edge (GA);
\path [-stealth] (HB) edge (GB);
\path [-stealth] (phi) edge (GA);
\path [-stealth] (phi) edge (GB);
\end{tikzpicture}
</script> <i><font color="#0093af">Probabilistic graphical model for the decomposition of the data generation process illustrating the record linkage problem we tackle with a Stochastic EM.</font></i> <br/> <br/> </div> </div> <p><br/> To wit, the parameter \(\eta\) aligns with the multinomial distribution of each PIV. From the observed registered data \(G^A\) and \(G^B,\) we generate underlying credible true values \(H^A\) and \(H^B\) factoring in potential missing values and mistakes with \(\phi.\) By comparing the latent information generated for the records supposedly referring to the same entities, we account for changes between the information collected in file \(A\) and in file \(B\) with \(\alpha.\) (The place of residence is likely to change through the years for instance). We then use blocking techniques to build plausible pairs, that are those which connect records when their true values agree together for stable PIVs (which are thought not to evolve over time). We evaluate the contribution of each candidate pair to the complete data likelihood and decide whether to accept or reject it. We finally fit the probability for a record in file \(A\) to form a link with a record in file \(B\) with \(\gamma.\) We sketch the outline of the methodology in the probabilistic graphical model above.</p> <p>In the paper, we illustrate the ability of our methodology to connect observations using two large real data applications and demonstrate the robustness of our model to the linking variables quality in a simulation study.</p> <div class="links"> <a href="http://arxiv.org/pdf/1403.0211.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="links"> <a href="assets/pdf/example_pdf.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="container-link-button"> <a href="http://arxiv.org/pdf/1403.0211.pdf" target="_blank" class="btncv z-depth-0">doc</a> </div> <p>The proposed algorithm FlexRL is available in R and the code is available on github, as well as complementary materials:</p> <div class="repositories d-flex flex-wrap flex-md-row flex-column justify-content-between align-items-center"> <div class="repo p-2 text-center"> <a href="https://github.com/robachowyk/RecordLinkage/tree/main/FlexRL"> <img class="repo-img-light w-100" alt="robachowyk/RecordLinkage/tree/main/FlexRL" src="https://github-readme-stats.vercel.app/api/pin/?username=robachowyk&amp;repo=RecordLinkage&amp;theme=vue&amp;show_owner=false"/> <img class="repo-img-dark w-100" alt="robachowyk/RecordLinkage/tree/main/FlexRL" src="https://github-readme-stats.vercel.app/api/pin/?username=robachowyk&amp;repo=RecordLinkage&amp;theme=tokyonight&amp;show_owner=false"/> </a> </div> </div>]]></content><author><name></name></author><category term="sample-posts"/><category term="RL"/><category term="LatentModel"/><category term="PIVs"/><category term="StEM"/><summary type="html"><![CDATA[Stochastic Expectation Maximisation for combining information spread over two files]]></summary></entry><entry><title type="html">When random matrix theory meets theoretical ecology</title><link href="https://kayanerobach.github.io/blog/2023/rmt-theoretical-ecology/" rel="alternate" type="text/html" title="When random matrix theory meets theoretical ecology"/><published>2023-01-27T11:46:00+00:00</published><updated>2023-01-27T11:46:00+00:00</updated><id>https://kayanerobach.github.io/blog/2023/rmt-theoretical-ecology</id><content type="html" xml:base="https://kayanerobach.github.io/blog/2023/rmt-theoretical-ecology/"><![CDATA[<p>This is an example post with blablabla</p> <div class="repositories d-flex flex-wrap flex-md-row flex-column justify-content-between align-items-center"> <div class="repo p-2 text-center"> <a href="https://github.com/robachowyk/RMTTheoreticalEcology"> <img class="repo-img-light w-100" alt="robachowyk/RMTTheoreticalEcology" src="https://github-readme-stats.vercel.app/api/pin/?username=robachowyk&amp;repo=RMTTheoreticalEcology&amp;theme=vue&amp;show_owner=false"/> <img class="repo-img-dark w-100" alt="robachowyk/RMTTheoreticalEcology" src="https://github-readme-stats.vercel.app/api/pin/?username=robachowyk&amp;repo=RMTTheoreticalEcology&amp;theme=tokyonight&amp;show_owner=false"/> </a> </div> </div>]]></content><author><name></name></author><category term="sample-posts"/><category term="RMT"/><category term="TheoreticalEcology"/><category term="P-matrix"/><category term="LotkaVolterra"/><summary type="html"><![CDATA[Study of the phase transition phenomena for the feasibility, Volterra Lyapunov stability and P-property in Lotka Volterra models]]></summary></entry></feed>