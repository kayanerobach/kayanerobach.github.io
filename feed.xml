<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://kayanerobach.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://kayanerobach.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-02-24T20:28:14+00:00</updated><id>https://kayanerobach.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Flexible Record Linkage</title><link href="https://kayanerobach.github.io/blog/2025/flexible-record-linkage/" rel="alternate" type="text/html" title="Flexible Record Linkage"/><published>2025-02-12T16:34:00+00:00</published><updated>2025-02-12T16:34:00+00:00</updated><id>https://kayanerobach.github.io/blog/2025/flexible-record-linkage</id><content type="html" xml:base="https://kayanerobach.github.io/blog/2025/flexible-record-linkage/"><![CDATA[<h3 id="overview">Overview</h3> <p>Combining data from various sources such as observational studies and municipality registries or hospital databases empowers researchers to explore innovative questions and improve models. However, the lack of a unique identifier often poses challenges. Natural problems like counting casualties require distinguishing individuals in registers that may contain duplicates when bodies are listed by several organisations. Conducting healthcare longitudinal studies require follow up information that is often concealed due to privacy considerations.</p> <p>Record linkage procedures determine whether pairs of observations collected on different occasions belong to the same individual using partially identifying variables (e.g. initials, birth year, zipcode), hereafter denoted PIVs. The complexity of this problem stems from the sub-par reliability of the PIVs used to link records and their limited number of unique values. Furthermore, because entities are often uniquely represented in each file, records from one file can maximally be linked with one record in the other file, making the linkage decisions interdependent.</p> <p>We propose a Stochastic Expectation Maximisation to combine observations from two overlapping data sets, that adapts to varying data complexities, addressing registration errors, including mistakes and missing values, and accommodating changes of the identifying information over time. Taking account of zip code temporal dynamics holds importance in healthcare longitudinal studies; in the particular case of survival analysis, long term follow-up are crucial, which increases the probability to move.</p> <h3 id="article">Article</h3> <p>In the paper, we explain our methodology and we illustrate the ability of our methodology to connect observations using two large real data applications and demonstrate the robustness of our model to the linking variables quality in a simulation study. <br/></p> <div style="margin-left: 30px;"> <a href="https://doi.org/10.1093/jrsssc/qlaf016" target="_blank" rel="noopener noreferrer"> <i class="fa-solid fa-file-lines" title="JRSSC" style="font-size: 74px;"></i> </a> </div> <p><br/></p> <div style="margin-left: 30px;"> <a href="https://arxiv.org/pdf/2407.06835" target="_blank" rel="noopener noreferrer"> <i class="fa-solid fa-file" title="Arxiv" style="font-size: 74px;"></i> </a> </div> <p><br/> The proposed algorithm FlexRL, written in R and Cpp is <a href="https://cran.r-project.org/web/packages/FlexRL/index.html">available on CRAN</a>. The development version of the code, experiments and data sets are available on GitHub. <br/></p> <div class="repositories d-flex flex-wrap flex-md-row flex-column justify-content-between align-items-center"> <div class="repo p-2 text-center"> <a href="https://github.com/robachowyk/FlexRL-experiments"> <img class="repo-img-light w-100" alt="robachowyk/FlexRL-experiments" src="https://github-readme-stats.vercel.app/api/pin/?username=robachowyk&amp;repo=FlexRL-experiments&amp;theme=vue&amp;show_owner=false"/> <img class="repo-img-dark w-100" alt="robachowyk/FlexRL-experiments" src="https://github-readme-stats.vercel.app/api/pin/?username=robachowyk&amp;repo=FlexRL-experiments&amp;theme=tokyonight&amp;show_owner=false"/> </a> </div> </div> <p><br/></p> <p><i>Cite the paper:</i> <br/> @article{robach2025, <br/> title = {A flexible model for Record Linkage}, <br/> author = {Robach, K. and van der Pas, S. L. and van de Wiel, M. A. and Hof, M. H.}, <br/> year = {2025}, <br/> journal = {Journal of the Royal Statistical Society: Series C} <br/> }</p> <p><i>Cite the package:</i> <br/> @Manual{flexrlpackage, <br/> title = {FlexRL}, <br/> author = {Robach, K. and Hof, M. H.}, <br/> year = {2025}, <br/> note = {R package}, <br/> url = {https://cran.r-project.org/web/packages/FlexRL/index.html}, <br/> organization = {CRAN} <br/> }</p> <h3 id="technical-details">Technical details</h3> <p>To estimate the common set of records, we build a statistical model that leverages the latent representation of the partially identifying information embedded in the data generation process, and derive a probabilistic estimate that allows for inference. We estimate the model parameters represented as input nodes on the probabilistic graphical model hereafter, using a Stochastic Expectation Maximisation algorithm. <br/></p> <div class="exampletest"> <div align="center"> <br/> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/FlexRL-480.webp 480w,/assets/img/FlexRL-800.webp 800w,/assets/img/FlexRL-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/FlexRL.png" class="img-fluid" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <script type="text/tikz">
\begin{tikzpicture}
\node[draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (gamma) at (0,4) {$\gamma$};
\node[shape=circle, draw={rgb:red,0;green,147;blue,175}, dashed, minimum size=1cm] (delta) at (0,2) {$\Delta$};
\node[draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (eta) at (0,0) {$\eta$};
\node[draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (alpha) at (0,-2) {$\alpha$};
\node[shape=circle, dashed, draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (HA) at (-3,-2) {$H^A$};
\node[shape=circle, dashed, draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (HB) at (3,-2) {$H^B$};
\node[draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (phi) at (0,-4) {$\phi$};
\node[shape=circle, draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (GA) at (-4.5,-4) {$G^A$};
\node[shape=circle, draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (GB) at (4.5,-4) {$G^B$};
\path [-stealth] (gamma) edge (delta);
\path [-stealth] (delta) edge (HA);
\path [-stealth] (delta) edge (HB);
\path [-stealth] (eta) edge (HA);
\path [-stealth] (eta) edge (HB);
\path [-stealth] (alpha) edge (HA);
\path [-stealth] (alpha) edge (HB);
\path [-stealth] (HA) edge (GA);
\path [-stealth] (HB) edge (GB);
\path [-stealth] (phi) edge (GA);
\path [-stealth] (phi) edge (GB);
\end{tikzpicture}
</script> <i><font color="#0093af">Probabilistic graphical model for the decomposition of the data generation process illustrating the record linkage problem we tackle with a Stochastic EM.</font></i> <br/> <br/> </div> </div> <p><br/> To wit, the parameter \(\eta\) aligns with the multinomial distribution of each PIV. From the observed registered data \(G^A\) and \(G^B,\) we generate underlying credible true values \(H^A\) and \(H^B\) factoring in potential missing values and mistakes with \(\phi.\) By comparing the latent information generated for the records supposedly referring to the same entities, we account for changes between the information collected in file \(A\) and in file \(B\) with \(\alpha.\) (The place of residence is likely to change through the years for instance). We then use blocking techniques to build plausible pairs, that are those which connect records when their true values agree together for stable PIVs (which are thought not to evolve over time). We evaluate the contribution of each candidate pair to the complete data likelihood and decide whether to accept or reject it. We finally fit the probability for a record in file \(A\) to form a link with a record in file \(B\) with \(\gamma.\) We sketch the outline of the methodology in the probabilistic graphical model above.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="RecordLinkage,"/><category term="LatentVariables,"/><category term="StEM"/><summary type="html"><![CDATA[A STochastic Expectation Maximisation approach to Record Linkage]]></summary></entry><entry><title type="html">False Discovery estimation in Record Linkage</title><link href="https://kayanerobach.github.io/blog/2025/false-discovery/" rel="alternate" type="text/html" title="False Discovery estimation in Record Linkage"/><published>2025-02-12T16:34:00+00:00</published><updated>2025-02-12T16:34:00+00:00</updated><id>https://kayanerobach.github.io/blog/2025/false-discovery</id><content type="html" xml:base="https://kayanerobach.github.io/blog/2025/false-discovery/"><![CDATA[<h3 id="overview">Overview</h3> <p>Combining data from various sources such as observational studies and municipality registries or hospital databases empowers researchers to explore innovative questions and improve models. However, the lack of a unique identifier often poses challenges. Natural problems like counting casualties require distinguishing individuals in registers that may contain duplicates when bodies are listed by several organisations. Conducting healthcare longitudinal studies require follow up information that is often concealed due to privacy considerations.</p> <p>Record linkage procedures determine whether pairs of observations collected on different occasions belong to the same individual using partially identifying variables (e.g. initials, birth year, zipcode), hereafter denoted PIVs. The complexity of this problem stems from the sub-par reliability of the PIVs used to link records and their limited number of unique values. Furthermore, because entities are often uniquely represented in each file, records from one file can maximally be linked with one record in the other file, making the linkage decisions interdependent.</p> <p>We propose a Stochastic Expectation Maximisation to combine observations from two overlapping data sets, that adapts to varying data complexities, addressing registration errors, including mistakes and missing values, and accommodating changes of the identifying information over time. Taking account of zip code temporal dynamics holds importance in healthcare longitudinal studies; in the particular case of survival analysis, long term follow-up are crucial, which increases the probability to move.</p> <h3 id="article">Article</h3> <p>In the paper, we explain our methodology and we illustrate the ability of our methodology to connect observations using two large real data applications and demonstrate the robustness of our model to the linking variables quality in a simulation study. <br/></p> <div style="margin-left: 30px;"> <a href="https://doi.org/10.1093/jrsssc/qlaf016" target="_blank" rel="noopener noreferrer"> <i class="fa-solid fa-file-lines" title="JRSSC" style="font-size: 74px;"></i> </a> </div> <p><br/></p> <div style="margin-left: 30px;"> <a href="https://arxiv.org/pdf/2407.06835" target="_blank" rel="noopener noreferrer"> <i class="fa-solid fa-file" title="Arxiv" style="font-size: 74px;"></i> </a> </div> <p><br/> The proposed algorithm FlexRL, written in R and Cpp is <a href="https://cran.r-project.org/web/packages/FlexRL/index.html">available on CRAN</a>. The development version of the code, experiments and data sets are available on GitHub. <br/></p> <div class="repositories d-flex flex-wrap flex-md-row flex-column justify-content-between align-items-center"> <div class="repo p-2 text-center"> <a href="https://github.com/robachowyk/FlexRL-experiments"> <img class="repo-img-light w-100" alt="robachowyk/FlexRL-experiments" src="https://github-readme-stats.vercel.app/api/pin/?username=robachowyk&amp;repo=FlexRL-experiments&amp;theme=vue&amp;show_owner=false"/> <img class="repo-img-dark w-100" alt="robachowyk/FlexRL-experiments" src="https://github-readme-stats.vercel.app/api/pin/?username=robachowyk&amp;repo=FlexRL-experiments&amp;theme=tokyonight&amp;show_owner=false"/> </a> </div> </div> <p><i>Cite the paper:</i> @article{robach2025, title = {A flexible model for Record Linkage}, author = {Robach, K. and van der Pas, S. L. and van de Wiel, M. A. and Hof, M. H.}, year = {2025}, journal = {Journal of the Royal Statistical Society Series C: Applied Statistics} }</p> <p><i>Cite the package:</i> @Manual{flexrlpackage, title = {FlexRL}, author = {Robach, K. and Hof, M. H.}, year = {2025}, note = {R package}, url = {https://cran.r-project.org/web/packages/FlexRL/index.html}, organization = {CRAN} }</p> <h3 id="technical-details">Technical details</h3> <p>To estimate the common set of records, we build a statistical model that leverages the latent representation of the partially identifying information embedded in the data generation process, and derive a probabilistic estimate that allows for inference. We estimate the model parameters represented as input nodes on the probabilistic graphical model hereafter, using a Stochastic Expectation Maximisation algorithm. <br/></p> <div class="exampletest"> <div align="center"> <br/> <script type="text/tikz">
\begin{tikzpicture}
\node[draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (gamma) at (0,4) {$\gamma$};
\node[shape=circle, draw={rgb:red,0;green,147;blue,175}, dashed, minimum size=1cm] (delta) at (0,2) {$\Delta$};
\node[draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (eta) at (0,0) {$\eta$};
\node[draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (alpha) at (0,-2) {$\alpha$};
\node[shape=circle, dashed, draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (HA) at (-3,-2) {$H^A$};
\node[shape=circle, dashed, draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (HB) at (3,-2) {$H^B$};
\node[draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (phi) at (0,-4) {$\phi$};
\node[shape=circle, draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (GA) at (-4.5,-4) {$G^A$};
\node[shape=circle, draw={rgb:red,0;green,147;blue,175}, minimum size=1cm] (GB) at (4.5,-4) {$G^B$};
\path [-stealth] (gamma) edge (delta);
\path [-stealth] (delta) edge (HA);
\path [-stealth] (delta) edge (HB);
\path [-stealth] (eta) edge (HA);
\path [-stealth] (eta) edge (HB);
\path [-stealth] (alpha) edge (HA);
\path [-stealth] (alpha) edge (HB);
\path [-stealth] (HA) edge (GA);
\path [-stealth] (HB) edge (GB);
\path [-stealth] (phi) edge (GA);
\path [-stealth] (phi) edge (GB);
\end{tikzpicture}
</script> <i><font color="#0093af">Probabilistic graphical model for the decomposition of the data generation process illustrating the record linkage problem we tackle with a Stochastic EM.</font></i> <br/> <br/> </div> </div> <p><br/> To wit, the parameter \(\eta\) aligns with the multinomial distribution of each PIV. From the observed registered data \(G^A\) and \(G^B,\) we generate underlying credible true values \(H^A\) and \(H^B\) factoring in potential missing values and mistakes with \(\phi.\) By comparing the latent information generated for the records supposedly referring to the same entities, we account for changes between the information collected in file \(A\) and in file \(B\) with \(\alpha.\) (The place of residence is likely to change through the years for instance). We then use blocking techniques to build plausible pairs, that are those which connect records when their true values agree together for stable PIVs (which are thought not to evolve over time). We evaluate the contribution of each candidate pair to the complete data likelihood and decide whether to accept or reject it. We finally fit the probability for a record in file \(A\) to form a link with a record in file \(B\) with \(\gamma.\) We sketch the outline of the methodology in the probabilistic graphical model above.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="RecordLinkage,"/><category term="FalseDiscoveryRate"/><summary type="html"><![CDATA[A method for estimating the FDR in RL]]></summary></entry><entry><title type="html">When random matrix theory meets theoretical ecology</title><link href="https://kayanerobach.github.io/blog/2022/rmt-theoretical-ecology/" rel="alternate" type="text/html" title="When random matrix theory meets theoretical ecology"/><published>2022-11-27T11:46:00+00:00</published><updated>2022-11-27T11:46:00+00:00</updated><id>https://kayanerobach.github.io/blog/2022/rmt-theoretical-ecology</id><content type="html" xml:base="https://kayanerobach.github.io/blog/2022/rmt-theoretical-ecology/"><![CDATA[<h3 id="overview">Overview</h3> <p>This is an investigation on the P-property of the inverse of a random matrix under positive diagonal deformation. This project is driven by the objective of understanding properties of large dynamic Lotka Volterra systems equilibria for theoretical ecology.</p> <h3 id="supporting-information">Supporting information</h3> <p><br/></p> <div style="margin-left: 30px;"> <a href="/assets/pdf/RMTreport.pdf" target="_blank" rel="noopener noreferrer"> <i class="fa-solid fa-file-pen" title="Report" style="font-size: 74px;"></i> </a> </div> <p><br/></p> <div style="margin-left: 30px;"> <a href="/assets/pdf/RMTprez.pdf" target="_blank" rel="noopener noreferrer"> <i class="fa-solid fa-file-image" title="Slides" style="font-size: 74px;"></i> </a> </div> <p><br/></p> <h3 id="from-the-p-property-to-regularity-of-an-interval-matrix">From the P-property to regularity of an interval matrix</h3> \[I_N - \Gamma_N \text{ P-matrix} \iff \left[ -2 {\Gamma_N}^{-1}, -2 {\Gamma_N}^{-1} + 2 I_N \right] \text{ is regular}\] <p>Matrices in this interval have the form: \(-2 {\Gamma_N}^{-1} + \Delta\), where \(\Delta\) is a diagonal matrix with entries in \([0,2]\).</p> <p>The challenge consist in showing that the interval contains no singular matrix.</p> <h3 id="jiri-rohns-algorithm">Jiri Rohn’s algorithm</h3> <div class="repositories d-flex flex-wrap flex-md-row flex-column justify-content-between align-items-center"> <div class="repo p-2 text-center"> <a href="https://github.com/robachowyk/RMTTheoreticalEcology"> <img class="repo-img-light w-100" alt="robachowyk/RMTTheoreticalEcology" src="https://github-readme-stats.vercel.app/api/pin/?username=robachowyk&amp;repo=RMTTheoreticalEcology&amp;theme=vue&amp;show_owner=false"/> <img class="repo-img-dark w-100" alt="robachowyk/RMTTheoreticalEcology" src="https://github-readme-stats.vercel.app/api/pin/?username=robachowyk&amp;repo=RMTTheoreticalEcology&amp;theme=tokyonight&amp;show_owner=false"/> </a> </div> </div> <p>Consider an exhaustive list of methods to determine the <strong>REG</strong>ular<strong>I</strong>ty or the <strong>SING</strong>ularity of the interval \([A_c - \Delta, A_c + \Delta]\) where \(A_c = (A - I)^{-1} (A + I)\) and \(\Delta = I\); \(A\) being a matrix of size \((n \times n)\) and \(I\) the identity matrix of size \((n \times n)\).</p> <p><strong>Conditions for the existence of a singular matrix</strong></p> <ul> <li> <p><em>midpoint matrix</em> \(A_c\): the midpoint matrix \(A_c\) of the interval matrix \([A_c \pm \Delta]\) is singular.</p> </li> <li> <table> <tbody> <tr> <td><em>diagonal condition</em> <a href="https://doi.org/10.1137/S0895479896310743">Theorem 2.1 from Oettli and Prager</a>: $$</td> <td>A_c x</td> <td>\leq \Delta</td> <td>x</td> <td>\(has a non trivial (i.e. non zero) solution\)x$$.</td> </tr> </tbody> </table> </li> <li> <p><em>steepest determinant descent</em> <a href="https://doi.org/10.1016/0024-3795(89)90004-9">Algorithm 5.1</a>: investigate determinant bounds of the interval matrix (i.e. the hull of matrices determinant for matrices in the interval).</p> </li> <li> <p><em>two Qz-matrices</em> <a href="https://doi.org/10.1137/S0895479896313978">Theorem 4.3</a>: the linear programming problem \((\star)\) maximize \(z^T x\) subject to \((A_c - \Delta \cdot diag(z)) x \leq 0$ and $diag(z) \cdot x \geq 0\), is unbounded for some \(z \in \{ \pm 1 \}^n\).</p> </li> <li> <p><em>main algorithm</em> <a href="https://doi.org/10.1137/0614007">Theorem 2.2 - find the singular matrix</a>: loop on \(\{ \pm 1 \}^n\) to identify the possible singular matrix which should have the specific form.</p> </li> <li><em>symmetrization</em> <a href="https://doi.org/10.1137/S0895479896310743">Sections 4 and 5 from Rex and Rohn</a>: both of the following conditions imply the singularity of \([A_c \pm \Delta]\): <ul> <li> \[\lambda_{\max}({A_c}^T A_c) \leq \lambda_{\min}(\Delta^T \Delta)\] </li> <li>\(\Delta^T \Delta - {A_c}^T A_c\) positive definite</li> </ul> </li> </ul> <p><strong>Conditions for the regularity of the interval</strong></p> <ul> <li> <table> <tbody> <tr> <td><em>Beeck’s condition</em> <a href="https://doi.org/10.1137/S0895479896310743">Corollary 3.2 from Beeck</a>: $$\rho (</td> <td>{A_c}^{-1}</td> <td>\Delta) &lt; 1\(is regular (for\)A_c$$ non singular).</td> </tr> </tbody> </table> </li> <li><em>symmetrization</em> <a href="https://doi.org/10.1137/S0895479896310743">Sections 4 and 5 from Rex and Rohn</a>: both of the following conditions imply the regularity of \([A_c \pm \Delta]\): <ul> <li> \[\lambda_{\max}(\Delta^T \Delta) &lt; \lambda_{\min}({A_c}^T A_c)\] </li> <li> <table> <tbody> <tr> <td>$${A_c}^T A_c -</td> <td>\Delta^T \Delta</td> <td>I$$ is positive definite</td> </tr> </tbody> </table> </li> </ul> </li> <li> <p><em>two Qz-matrices</em> <a href="https://doi.org/10.1137/S0895479896313978">Theorem 4.3</a>: the linear programming problem \((\star)\) is bounded for all \(z \in \{ \pm 1 \}^n\).</p> </li> <li><em>main algorithm</em> <a href="https://doi.org/10.1137/0614007">Theorem 2.2 - all matrices are non singular</a>: loop on \(\{ \pm 1 \}^n\) to check there is no singular matrix in the whole interval. This last track is the most expensive since the algorithm will investigate the values of the sign real spectral radius.</li> </ul>]]></content><author><name></name></author><category term="sample-posts"/><category term="RMT"/><category term="TheoreticalEcology"/><category term="P-matrix"/><category term="LotkaVolterra"/><summary type="html"><![CDATA[Study of the phase transition phenomena for the feasibility, Volterra Lyapunov stability and P-property in Lotka Volterra models]]></summary></entry></feed>